{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There has been a lot of buzz surrounding the area of autonomous driving and GANs. Modern deep learning has almost become synonyms with the output of a particular class of neural networks. In this notebook, we meet these beasts and call them \"Convolutional Neural Networks\". We shall explore what convolution is, what does a convolutional layer do and then build our very first classifier. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutions Demystified "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to understand convolutional neural networks, we need to understand what a convolution operation does. Now, If I went a \"convolution is an operation that computes the average of everything in a fixed window\" you'll probably groan internally. I'm gonna be better and show you visually how a convolution looks like for an image. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ConvGif](imgs/conv_moving.gif \"conv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gif is a neat little visualization of what a convolution operation is. Essentially, a convolution operation is to compute the **weighted average** of a given fixed (height, width) region in an image. The weights are provided by what is called a _kernel_. So in this figure above, the blue square is the image and the red square is the output of the convolution. The green moving square is the kernel. We usually have kernels which have _odd_ height and width (we'll explain this shortly). For now, let's keep this definition in mind while we study the other elements of convolutional neural networks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elements of CNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a working definition of convolution we can focus on other components that make up a convolutional neural networks. We'll introduce the convolutional layer, the pooling operation and ReLU before desigining our first CNN!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image](imgs/depthcol.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This figure shows what a convolutional layer does. The red square represents an image. We say an image has a `height`, `width` and `depth`. The height and width are intutitive (in this figure they are 32 respectively). The `depth` parameter is a little harder to understand. I'll try to explain it in a good way however.\n",
    "\n",
    "\n",
    "If you consider a color image, it's composed of three colors R,G,B. Now a computer only understands binary so we need to have one dataholder for red, one for green and so on. These are called _channels_ of an image. Now a way to visualize this is to imagine the red square as a _stack_ of these channels. What a convolutional layer does is it computes the convolution in the (`kernel_height`, `kernel_width`) regions for _all_ the channels. And this is the key thing that makes convolutional layers so effective - unlike fully connected layers, the input neurons are not connected to _all_ output neurons. Rather they are connected in a specific region defined by `kernel height` $H$ and `kernel_width` $W$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image](imgs/maxpool.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a `maxpool` layer. This is a very simple layer, that simply returns the maximum value in a ($H$, $W$) region. However, the motivation behind this is powerful. We select the maximum in a given window because we interpret anything that's not only above the activation threshold, but also greater than any other values in its nearby region as being _most important_. Thus it makes sense to only look in that region for anything of value. The stride $S$ of a max pool or a convolutional filter is the _step size_ it takes. This is similar to incrementing a variable in a for loop by a fixed amount."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image](imgs/relu.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last bit of theory I swear! \n",
    "\n",
    "This is the ReLU nonlinearity that is used. Mathematically it's simple $relu(x) = max(0,x)$. Essentially, this is a thresholding operation that rejects any value below zero. This is typically applied as nonlinearity between different layers in a CNN. There are other variants to it, but we'll dicuss it ......sometime."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programming CNNs in Keras "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally! We get to coding our very first CNN in Keras. In this we'll be using the [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html) dataset to classify objects. The CIFAR-10 dataset has about 60000 images in its training set, each having a dimension of $(32,3,3)$. As before we'll start by arranging components first and then building APIs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# necessary imports \n",
    "import keras \n",
    "import os, time \n",
    "import matplotlib.pyplot as plt\n",
    "from keras import Sequential "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports for convolutional layers \n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from keras import Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              8389632   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 8,660,042\n",
      "Trainable params: 8,660,042\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# We're going to create the vision model in the same way we created our input model. However whenever you create \n",
    "# a new convolutional layer you need to keep in mind 3 things \n",
    "# 1. The number of output channels of the layer. \n",
    "# 2. The kernel size \n",
    "# 3. The stride and padding. \n",
    "\n",
    "model = Sequential() \n",
    "# input layer \n",
    "model.add(Conv2D(64, (3,3), padding='same', activation='relu', input_shape=(32,32,3)))\n",
    "model.add(Conv2D(64, (3,3), padding='same', activation='relu'))\n",
    "# adding pooling \n",
    "model.add(MaxPooling2D(2,2))\n",
    "model.add(Conv2D(128, (3,3), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(2,2))\n",
    "model.add(Conv2D(128, (3,3), padding='same', activation='relu'))\n",
    "model.add(Flatten()) # flatten the input vector into a 1D shape \n",
    "model.add(Dense(1024, activation='relu')) # we met these in the last notebook \n",
    "model.add(Dense(10, activation='softmax')) # the final output\n",
    "\n",
    "\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this code snippet we create a tiny CNN. The input layer accepts an input shape which varies according to the images in your dataset. The first parameter in the call to `Conv2D` tells us how many output _activation maps_ we want from this layer. So you can read the a call to first `conv2d` layer as \"_we want to create a convolutional layer which outputs 64 activation maps, by looking in a $(3x3)$ area, and an input shape of $(32,32,3)$_\". Similarly you can read the other layers with the exception that the other convolutional layers do not explicitly specify an `input_shape` parameter. Keras automagically handles this by deducing the input shapes for you. Neat!\n",
    "\n",
    "If you run this cell, it'll work (but it doesn't produce anything yet, just creates a convolutional model in memory). However, this is terribly repetitive, wouldn't it be better if we could make some sort of function that could return a model with all the layers instantiated. We could then customize the argument to that function and obtain a different neural network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1024)              8389632   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 8,660,042\n",
      "Trainable params: 8,660,042\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def create_cnn(layer_config, input_shape):\n",
    "    \"\"\"\n",
    "    Creates a convolutional neural network \n",
    "    to be used with Keras.\n",
    "    \n",
    "    NOTE: All activations are assumed to be Relu units.\n",
    "    \n",
    "    Args:\n",
    "    1. layer_config: A list of tuples specifiying the size of the \n",
    "    layers. By default the first layer is assumed to be the input. \n",
    "    We define the following mapping for creating different layers: \n",
    "    (c, 64, 3) -> Create a conv2d with 64 output channels and kernel size of 3\n",
    "    (m, 2) -> Create a maxpooling2d with kernel size of 2x2 \n",
    "    (d, 1024) -> create a dense layer with 1024 units \n",
    "    (f, None) -> flatten the convolutional layer.\n",
    "    \n",
    "    2. Input shape: The input shape \n",
    "    \n",
    "    Returns:\n",
    "    A sequential Keras model \n",
    "    \"\"\"\n",
    "    a_model = Sequential()\n",
    "    for i, layer in enumerate(layer_config):\n",
    "        if i == 0 and layer[0] == 'c':\n",
    "            a_model.add(Conv2D(layer[1], (layer[2],layer[2]), padding='same', activation='relu', input_shape=input_shape))\n",
    "        elif layer[0] == 'c':\n",
    "            a_model.add(Conv2D(layer[1], (layer[2],layer[2]), padding='same', activation='relu'))\n",
    "        \n",
    "        if layer[0] == 'm':\n",
    "            a_model.add(MaxPooling2D((layer[1], layer[1])))\n",
    "        \n",
    "        if layer[0] == 'f':\n",
    "            a_model.add(Flatten())\n",
    "            \n",
    "        if i == len(layer_config)-1 and layer[0] == 'd':\n",
    "            a_model.add(Dense(layer[1], activation='softmax'))\n",
    "        elif layer[0] == 'd':\n",
    "            a_model.add(Dense(layer[1], activation='relu'))\n",
    "    \n",
    "    return a_model\n",
    "\n",
    "\n",
    "# using the definition we have above \n",
    "layer_config=[('c',64,3), ('c',64,3),('m',2), ('c',128, 3), ('m',2), ('c',128,3), ('f',None),('d',1024),('d',10)]\n",
    "\n",
    "vis_model = create_cnn(layer_config, input_shape=(32,32,3))\n",
    "print(vis_model.summary())\n",
    "     \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome! Now we have a function that we can use to create any neural network for ourselves by just specifying the `layer_config`. Let's train the model now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the CNN \n",
    "\n",
    "In  this section we're going to load the CIFAR-10 data and train for two epochs before evaluating the model on testing set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the keras cifar-10 loader \n",
    "from keras.datasets import cifar10\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As before we shall convert our labels to one-hot encoding for easier computation \n",
    "\n",
    "y_train_cat = keras.utils.to_categorical(y_train, num_classes=10)\n",
    "y_test_cat = keras.utils.to_categorical(y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# lets see what a label looks like \n",
    "print(y_train_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now lets compile our vision model \n",
    "vis_model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.4942 - acc: 0.1001\n",
      "Epoch 2/2\n",
      "50000/50000 [==============================] - 8s 161us/step - loss: 14.5063 - acc: 0.1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc19c38bd68>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And now lets train our model on the trianing set. We'll train for two epochs, with a batch size of 100 \n",
    "\n",
    "vis_model.fit(x=x_train, y=y_train_cat, batch_size=100, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 106us/step\n",
      "test loss:14.506285661315918\n",
      "test accuracy:0.1\n"
     ]
    }
   ],
   "source": [
    "# Lets evaluate now\n",
    "\n",
    "score = vis_model.evaluate(x=x_test, y=y_test_cat)\n",
    "print(\"test loss:{}\".format(score[0]))\n",
    "print(\"test accuracy:{}\".format(score[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment: It's Convolutions all over!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You just learn a lot of information. These are some questions that make you think, experiment and learn more deeply about CNNs in general. \n",
    "\n",
    "\n",
    "1. Read the page here on convolutional neural network architecures -> [Convolutional Archs](http://cs231n.github.io/convolutional-networks/#architectures). Comprehend (and ask us questions) on different CNN architectures and why deep nets are the rage. \n",
    "\n",
    "\n",
    "2. Use `create_cnn` to create a CNN with:\n",
    "\n",
    "    i. Different kernel size of the convolutional layer. e.g (3,3) -> (5,5) or (7,7). Can you have an even number    as a kernel size? \n",
    "    \n",
    "    ii. Different number of output filters after the input layer.\n",
    "\n",
    "3. Train on CIFAR-10 data using:\n",
    "\n",
    "    i. Bigger batch size\n",
    "    \n",
    "    ii. More epochs \n",
    "    \n",
    "    Does any of this have any effect on `score`?\n",
    "\n",
    "4. Create a Convolutional network with 2 Convolutional, 1 MaxPooling and 2 Dense layers for MNIST-10. Do you observe better accuracy? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(bmw)",
   "language": "python",
   "name": "bmw"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
