{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron for Normalized GEMs\n",
    "\n",
    "Author: Brad Selee\n",
    "\n",
    "A PyTorch implementation of a feed-forward neural network to classify RNA expression matrices into cancerous or non-cancerous samples. This notebook reads in two files: the sample file which is the log transformed Gene Expression Matrix with quantile normalization.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, f1_scoreimport sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(data.Dataset):\n",
    "    'Characterizes a dataset for PyTorch'\n",
    "    def __init__(self, data, input_num_classes, output_num_classes):\n",
    "        \"\"\"\n",
    "        Initialization\n",
    "        data - normalized sample data 2 indexes wide the first index is the sample data and\n",
    "               the second index is the label (numpy array)\n",
    "        input_num_classes - represents the normalization range to create one-hot labels. \n",
    "        output_num_classes - number of labels that are being classified \n",
    "        \"\"\"\n",
    "        self.input_num_classes  = input_num_classes\n",
    "        self.output_num_classes = output_num_classes\n",
    "        self.data_input = data[0]\n",
    "        self.data_output = data[1]\n",
    "        assert len(self.data_input) == len(self.data_output)\n",
    "    \n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.data_input)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        # Select sample\n",
    "        '''\n",
    "        return (torch.nn.functional.one_hot(torch.tensor(self.data_input[index]),\n",
    "                                            num_classes=self.input_num_classes),\n",
    "                torch.nn.functional.one_hot(torch.tensor(self.data_output[index]),\n",
    "                                            num_classes=self.output_num_classes),)\n",
    "        '''\n",
    "        '''\n",
    "        return (torch.nn.functional.one_hot(torch.tensor(self.data_input[index]),\n",
    "                                            num_classes=self.input_num_classes),\n",
    "                torch.tensor(self.data_output[index]))\n",
    "        '''\n",
    "        return (torch.tensor(self.data_input[index]), torch.tensor(self.data_output[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: gain a better understanding of dropout layers\n",
    "class Net(nn.Module):\n",
    "    def __init__(self,  input_seq_length, input_num_classes, output_num_classes):\n",
    "        super(Net, self).__init__()\n",
    "        self.input_seq_length = input_seq_length\n",
    "        self.input_num_classes = input_num_classes\n",
    "        self.output_num_classes = output_num_classes\n",
    "\n",
    "        self.fc1 = nn.Linear(1*self.input_seq_length, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, 256)        \n",
    "        self.fc4 = nn.Linear(256, output_num_classes)\n",
    "        self.dropout = nn.Dropout(p=0.5, inplace=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.shape[0], 1*self.input_seq_length* 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        #x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        #x = self.dropout(x)\n",
    "        x = F.relu(self.fc3(x))\n",
    "        #x = self.dropout(x)\n",
    "        x = self.fc4(x)\n",
    "        # Note:\n",
    "        #   Softmax activation for output layer is not used because the nn.CrossEntropyLoss\n",
    "        #   automatically applies it, so we just send it the raw output. The most likely\n",
    "        #   class will be the index with the highest value. If probability is needed, the\n",
    "        #   softmax function can be called when calculating accuracy, this is shown in the\n",
    "        #   multi_acc function. Ultimately, the softmax as thelast activation function won't \n",
    "        #   change the classification result.\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labels_and_weights(label_file_df):\n",
    "    \"\"\" \n",
    "     Get list of unique sample labels and weights of the samples using\n",
    "     the inverse of the count. Weights is a tensor to be compatible with\n",
    "     CrossEntropyLoss.\n",
    "    \"\"\"\n",
    "        \n",
    "    labels_all = label_file_df.iloc[:,-1].astype(str).values.tolist()\n",
    "    labels_unique = set(labels_all)\n",
    "    labels = sorted(labels_unique)\n",
    "    \n",
    "    labels_count = [labels_all.count(label) for label in labels]\n",
    "    weights = 1. / torch.tensor(labels_count, dtype=torch.float) \n",
    "    \n",
    "    return labels, weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(matrix_transposed_df, label_file_df, num_classes=4):\n",
    "    \"\"\" merge sample and label file \"\"\"\n",
    "    \n",
    "    # Create dictionary of labels - key:labels, value:indices\n",
    "    labels = label_file_df.iloc[:,-1].astype(str).values.tolist()\n",
    "    labels_unique = set(labels)\n",
    "    labels = sorted(labels_unique)\n",
    "    labels_dict = {k:v for v, k in enumerate(labels)}\n",
    "    \n",
    "    merged_df = pd.merge(matrix_transposed_df, labels_df, left_index=True, right_on='sample')\n",
    "    del merged_df['sample']\n",
    "    merged_df['label'].replace(labels_dict, inplace=True)\n",
    "    \n",
    "    X = merged_df.iloc[:, 0:-1]\n",
    "    y = merged_df.iloc[:, -1]\n",
    "    \n",
    "    # stratify=y weights the train and test labels properly\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.3)\n",
    "    \n",
    "    return (X_train, y_train), (X_test, y_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(train_stats, test_stats, y_target_list, y_pred_list, labels,\n",
    "         graphs_title=\"Training vs Validation\", cm_title=\"Confusion Matrix\"):\n",
    "    \"\"\"Plot training/validation accuracy/loss and Confusion Matrix\"\"\"\n",
    "\n",
    "    # Set up dimensions for plots\n",
    "    dimensions = (7,12)\n",
    "    fig, axis = plt.subplots(figsize=dimensions)\n",
    "\n",
    "    # Plot CM\n",
    "    confusion_matrix_df = pd.DataFrame(confusion_matrix(y_target_list, y_pred_list))\n",
    "    sns_heatmap=sns.heatmap(confusion_matrix_df, ax=axis, annot=True, cbar=False,\n",
    "                                square=True, xticklabels=labels, yticklabels=labels)\n",
    "    axis.set_title(cm_title)\n",
    "    axis.set_ylabel(\"Actual\")\n",
    "    axis.set_xlabel(\"Predicted\")\n",
    "    \n",
    "    # Plot Accuracy\n",
    "    figure = plt.figure()\n",
    "    figure.set_figheight(12)\n",
    "    figure.set_figwidth(7)\n",
    "    plot1 = figure.add_subplot(211)\n",
    "    plot1.plot(train_stats['accuracy'])\n",
    "    plot1.plot(test_stats['accuracy'])\n",
    "    plot1.set_title(graphs_title)\n",
    "    plot1.set_ylabel(\"Accuracy\")\n",
    "    plot1.set_xlabel(\"Epoch\")\n",
    "    plt.legend([\"Training\", \"Testing\"], loc=\"upper left\")\n",
    "\n",
    "    # Plot Loss \n",
    "    plot2 = figure.add_subplot(212)\n",
    "    plot2.plot(train_stats['loss'])\n",
    "    plot2.plot(test_stats['loss'])\n",
    "    plot2.set_title(graphs_title)\n",
    "    plot2.set_ylabel(\"Loss\")\n",
    "    plot2.set_xlabel(\"Epoch\")\n",
    "    plot2.legend([\"Training\", \"Testing\"], loc=\"upper left\")\n",
    "\n",
    "    # Save plots into pdf\n",
    "    #plt.savefig(os.path.join(OUTPUT_DIR, 'stats.pdf'))\n",
    "    #sns_heatmap.figure.savefig(os.path.join(OUTPUT_DIR, \"confusion_matrix.pdf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_accuracy(actual_labels, predicted_labels):\n",
    "    \"\"\"Computes the accuracy for multiclass predictions\"\"\"\n",
    "    pred_labels_softmax = torch.softmax(predicted_labels, dim=1)\n",
    "    _, pred_labels_tags = torch.max(pred_labels_softmax, dim=1)\n",
    "\n",
    "    correct = (pred_labels_tags == actual_labels).float()\n",
    "    return correct.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(use_cuda)\n",
    "\n",
    "train_kwargs = {'batch_size': 16}\n",
    "test_kwargs = {'batch_size': 16}\n",
    "if use_cuda:\n",
    "    cuda_kwargs = {'num_workers': 1,\n",
    "                   'pin_memory': True,\n",
    "                   'shuffle': True}\n",
    "    train_kwargs.update(cuda_kwargs)\n",
    "    test_kwargs.update(cuda_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths\n",
    "SAMPLE_FILE = \"lung.emx.txt\"\n",
    "LABEL_FILE = \"sample_condition.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load Data\n",
    "matrix_df = pd.read_csv(SAMPLE_FILE, sep='\\t')\n",
    "matrix_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = (\"sample\", \"label\")\n",
    "labels_df = pd.read_csv(LABEL_FILE, names=column_names, delim_whitespace=True, header=None)\n",
    "labels, class_weights = labels_and_weights(labels_df)\n",
    "print(len(labels_df))\n",
    "print(len(matrix_df.columns))\n",
    "assert len(labels_df) == len(matrix_df.columns) \n",
    "print(len(labels_df))\n",
    "print(len(matrix_df.columns))\n",
    "print(labels)\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define parameters\n",
    "batch_size = 16\n",
    "max_epoch = 50\n",
    "learning_rate = 0.001 #5e-4\n",
    "num_features = len(matrix_df.index)\n",
    "num_classes = len(labels)\n",
    "\n",
    "## Create model structure\n",
    "model = Net(input_seq_length=num_features,\n",
    "          input_num_classes=10,\n",
    "          output_num_classes=num_classes).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, verbose=True, patience=50)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()#(weight=class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing and Visualizaiton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize missing data ~16k rows ~1400 columns\n",
    "# yellow => missing data\n",
    "plt.figure(figsize=(10, 7.5))\n",
    "sns.heatmap(matrix_df.isnull(), xticklabels=False, yticklabels=False, cmap=\"viridis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace nan values with the global minimum of the data set, not independent of rows\n",
    "# Then plot the density curve\n",
    "val_min, val_max = np.nanmin(matrix_df), np.nanmax(matrix_df)\n",
    "matrix_df.fillna(val_min, inplace=True)\n",
    "i = 0\n",
    "dimensions = (11.7, 8.27)\n",
    "fig, ax = plt.subplots(figsize=dimensions)\n",
    "for column in matrix_df:\n",
    "    i = i+1\n",
    "    sns.distplot(matrix_df[column], hist = False, ax=ax)\n",
    "    \n",
    "plt.title(\"Sample Distributions\")\n",
    "plt.xlabel(\"Expression Level\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.savefig(\"density.pdf\")\n",
    "print(i)\n",
    "print(matrix_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transposing matrix to align with label file\n",
    "matrix_transposed_df = matrix_df.T\n",
    "matrix_transposed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = split_data(matrix_transposed_df, labels_df, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert tuple of df's to tuple of np's\n",
    "# Allows the dataset class to access w/ data[][] instead of data[].iloc[]\n",
    "train_data_np = (train_data[0].values, train_data[1].values)\n",
    "test_data_np = (test_data[0].values, test_data[1].values)\n",
    "\n",
    "train_dataset = Dataset(train_data_np,input_num_classes=10, output_num_classes=num_classes)\n",
    "test_dataset = Dataset(test_data_np, input_num_classes=10,output_num_classes=num_classes)\n",
    "train_generator = data.DataLoader(train_dataset, **train_kwargs, drop_last=False)\n",
    "test_generator = data.DataLoader(test_dataset, **test_kwargs, drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and test the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Meter object to keep track of loss\n",
    "loss_avgmeter = AverageMeter()\n",
    "\n",
    "# Dataframes to keep track of statistics\n",
    "summary_file = pd.DataFrame([], columns=['Epoch', 'Training Loss', 'Accuracy', 'Accurate Count', 'Total Items'])\n",
    "train_stats = pd.DataFrame([], columns=['accuracy', 'loss'])\n",
    "test_stats = pd.DataFrame([], columns=['accuracy', 'loss'])\n",
    "\n",
    "for epoch in range(max_epoch):\n",
    "    model.train()\n",
    "    total_items = 0\n",
    "    acc = 0.0\n",
    "\n",
    "    # Training \n",
    "    for data, target in train_generator:\n",
    "        data = data.unsqueeze(1).float()\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        total_items += target.shape[0] \n",
    "        # Zero out the gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Predict in-sample labels and get training accuracy\n",
    "        prediction = model(data)\n",
    "        acc += multi_accuracy(target, prediction)\n",
    "        loss = loss_fn(prediction, target.long())\n",
    "        # Compute gradients and update weights\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Calculate loss per epoch\n",
    "    loss_avgmeter.update(loss.item(), batch_size)\n",
    "    acc_avg = acc/total_items\n",
    "    temp_stats = pd.DataFrame([[acc_avg, loss_avgmeter.avg]], columns=['accuracy', 'loss'])\n",
    "    train_stats = train_stats.append(temp_stats, ignore_index=True)\n",
    "\n",
    "    model.eval()\n",
    "    total_items = 0\n",
    "    correct = 0\n",
    "    acc = 0.0\n",
    "    acc_avg = 0.0\n",
    "    loss_avgmeter.reset()\n",
    "    \n",
    "    # Skip gradient calculation to improve speed\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Testing\n",
    "        for data, target in test_generator:\n",
    "            data = data.unsqueeze(1).float()\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            total_items += target.shape[0]\n",
    "            # Predict out-sample labels (samples network hasn't seen) and get validation accuracy\n",
    "            prediction = model(data)\n",
    "            acc += multi_accuracy(target, prediction)\n",
    "            loss = loss_fn(prediction, target.long())\n",
    "            loss_avgmeter.update(loss.item(), batch_size)\n",
    "    \n",
    "    acc_avg = acc/total_items\n",
    "    temp_stats = pd.DataFrame([[acc_avg, loss_avgmeter.avg]], columns=['accuracy', 'loss'])\n",
    "    test_stats = test_stats.append(temp_stats, ignore_index=True)\n",
    "\n",
    "    run_file = pd.DataFrame([['%d' %epoch, '%2.5f' %train_stats.iloc[epoch]['loss'], '%2.3f' %acc_avg, '%d' % acc, '%d' % total_items]], columns=['Epoch', 'Training Loss', 'Accuracy', 'Accurate Count', 'Total Items'])\n",
    "    print('Epoch: %d Training Loss: %2.5f Test Accuracy : %2.3f Accurate Count: %d Total Items :%d '% (epoch, train_stats.iloc[epoch]['loss'], acc_avg, acc, total_items))\n",
    "    scheduler.step(acc)\n",
    "    loss_avgmeter.reset()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to store predictions and actual labels for confusion matrix\n",
    "y_pred_list = []\n",
    "y_target_list = []\n",
    "\n",
    "# Run test set to get confusion matrix values\n",
    "with torch.no_grad():\n",
    "    for data, target in test_generator:\n",
    "        data = data.unsqueeze(1).float()\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        total_items += target.shape[0]\n",
    "        prediction = model(data)\n",
    "        prediction_softmax = torch.softmax(prediction, dim=1)\n",
    "        _, prediction_tags = torch.max(prediction_softmax, dim=1)\n",
    "        y_pred_list.append(prediction_tags.to('cpu'))\n",
    "        y_target_list.append(target.to('cpu'))\n",
    "\n",
    "y_pred_list = [j for val in y_pred_list for j in val]\n",
    "y_target_list = [j for val in y_target_list for j in val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(train_stats, test_stats, y_target_list, y_pred_list, labels,\n",
    "            graphs_title=\"lung.emx Plots\", cm_title=\"lung.emx Confusion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"f1 score: %0.2f\" % (f1_score(y_target_list, y_pred_list, average=\"weighted\")))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (mlbd)",
   "language": "python",
   "name": "mlbd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
