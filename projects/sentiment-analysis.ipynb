{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis for Movie Reviews\n",
    "\n",
    "Authors: Anthony Rizzo, Ben Shealy\n",
    "\n",
    "In this notebook, we will try to predict sentiment in online movie reviews using __natural language processing (NLP)__. We will use a dataset of Rotten Tomatoes reviews that was created via web-scraping by a Reddit user. The dataset can be obtained manually here:\n",
    "\n",
    "https://www.reddit.com/r/MachineLearning/comments/b5idqk/p_dataset_480000_rotten_tomatoes_reviews_for_nlp/\n",
    "\n",
    "You will need to install these additional packages in your conda environment:\n",
    "```\n",
    "conda install -y nltk tqdm\n",
    "```\n",
    "\n",
    "This project is a work in progress, so anyone is welcome to pick up this project and attempt to improve the results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import sklearn\n",
    "import sklearn.linear_model\n",
    "import sklearn.svm\n",
    "import tqdm\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the Rotten Tomatoes dataset as a pandas DataFrame\n",
    "movies_df = pd.read_csv(\"rotten_tomatoes_reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure there are no nulls in the data\n",
    "movies_df = movies_df[~movies_df.Freshness.isnull() & ~movies_df.Review.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show a preview of the DataFrame\n",
    "movies_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get a full count of words in the dataset\n",
    "n_words = 0\n",
    "for review in movies_df.Review:\n",
    "    n_words += len(review.split())\n",
    "\n",
    "print(\"Number of words: %d\" % n_words)\n",
    "print(\"Number of unique words: %d\" % len(np.unique(np.hstack(movies_df.Review))))\n",
    "print(\"Number of reviews: %d\" % len(movies_df))\n",
    "print(\"Average number of words per review: %d\" % (n_words // len(movies_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use X and y notation for data and labels\n",
    "X = movies_df.Review\n",
    "y = movies_df.Freshness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the Data\n",
    "\n",
    "The way you prepare your data can have a huge effect on the performance of your machine learning models. We've already removed missing values from the dataset, which is a basic requirement for most machine learning tasks. Since we are working with text data, another basic step is to remove punctuation and convert all text to lower-case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use regular expressions to remove punctuation and convert to lower-case\n",
    "REPLACE_NO_SPACE = re.compile(\"[.;:!\\'?,\\\"()\\[\\]]\")\n",
    "REPLACE_WITH_SPACE = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n",
    "\n",
    "def clean_reviews(reviews):\n",
    "    reviews = [REPLACE_NO_SPACE.sub(\"\", line.lower()) for line in reviews]\n",
    "    reviews = [REPLACE_WITH_SPACE.sub(\" \", line) for line in reviews]\n",
    "    return reviews\n",
    "\n",
    "X_cleaned = clean_reviews(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# before cleaning\n",
    "X[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after cleaning\n",
    "X_cleaned[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of unique words after cleaning: %d\" % len(np.unique(np.hstack(X_cleaned))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Evaluation\n",
    "\n",
    "Now that we've cleaned the reviews, we can evaluate a basic model just to see what accuracy we can achieve without any further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert reviews to a matrix of token counts\n",
    "count_vectorizer = sklearn.feature_extraction.text.CountVectorizer(binary=True)\n",
    "X_cv = count_vectorizer.fit_transform(X_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X_cv, y, test_size=0.25)\n",
    "\n",
    "# test initial feasibility of classification with logistic regression\n",
    "# also vary the regularization strength (C)\n",
    "best_clf = None\n",
    "best_score = 0\n",
    "\n",
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    # train model\n",
    "    clf = sklearn.linear_model.LogisticRegression(C=c, solver=\"lbfgs\", n_jobs=-1)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # evaluate model\n",
    "    score = clf.score(X_test, y_test)\n",
    "\n",
    "    # save best model\n",
    "    if best_score < score:\n",
    "        best_clf = clf\n",
    "        best_score = score\n",
    "    \n",
    "    # print model score\n",
    "    print(\"Accuracy for C=%0.2f: %0.3f\" % (c, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify the most informative faatures in the best model\n",
    "def show_most_informative_features(vectorizer, clf, n=10):\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    features = sorted(zip(clf.coef_[0], feature_names))\n",
    "    top = zip(features[:n], features[:-(n + 1):-1])\n",
    "\n",
    "    for (coef_1, fn_1), (coef_2, fn_2) in top:\n",
    "        print(\"  %.4f %-15s %.4f %-15s\" % (coef_1, fn_1, coef_2, fn_2))\n",
    "\n",
    "print(\"Most Informative Features (initial):\\n\")\n",
    "show_most_informative_features(count_vectorizer, best_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize the cleaned reviews\n",
    "freq = nltk.FreqDist()\n",
    "\n",
    "for review in tqdm.tqdm(X_cleaned):\n",
    "    for word in nltk.tokenize.word_tokenize(review):\n",
    "        freq[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot frequency distribution of top 20 words\n",
    "freq.plot(20, cumulative=False)\n",
    "freq.pprint(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# remove stop words from the dataset\n",
    "stop_words = set([\"the\", \"a\", \"and\", \"of\", \"to\", \"is\", \"in\", \"its\", \"it\", \"that\", \"but\", \"as\", \"with\", \"this\", \"for\", \"an\", \"on\", \"be\"])\n",
    "\n",
    "def remove_stopwords(reviews):\n",
    "    return [\" \".join([w for w in review.split() if w not in stop_words]) for review in tqdm.tqdm(reviews)]\n",
    "\n",
    "X_sw = remove_stopwords(X_cleaned)\n",
    "\n",
    "print(\"Before removing stop words:\", X_cleaned[1])\n",
    "print(\"After removing stop words:\", X_sw[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize the reviews with stop words removed\n",
    "freq = nltk.FreqDist()\n",
    "\n",
    "for review in tqdm.tqdm(X_sw):\n",
    "    for word in nltk.tokenize.word_tokenize(review):\n",
    "        freq[word] += 1\n",
    "\n",
    "freq.plot(20, cumulative=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert dataset to token counts again\n",
    "count_vectorizer = sklearn.feature_extraction.text.CountVectorizer(binary=True)\n",
    "X_sw_cv = count_vectorizer.fit_transform(X_sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate a logistic regression model again\n",
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X_sw_cv, y, test_size=0.25)\n",
    "\n",
    "best_clf = None\n",
    "best_score = 0\n",
    "\n",
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    clf = sklearn.linear_model.LogisticRegression(C=c, solver=\"lbfgs\", n_jobs=-1)\n",
    "    clf.fit(X_train, y_train)\n",
    "    score = clf.score(X_test, y_test)\n",
    "\n",
    "    if best_score < score:\n",
    "        best_clf = clf\n",
    "        best_score = score\n",
    "    \n",
    "    print(\"Accuracy for C=%0.2f: %0.3f\" % (c, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize different word forms into one using lemmatization with nltk\n",
    "def lemmatize_text(reviews):\n",
    "    lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "    return [\" \".join([lemmatizer.lemmatize(word) for word in review.split()]) for review in tqdm.tqdm(reviews)]\n",
    "\n",
    "X_sw_lm = lemmatize_text(X_sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sw_lm[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = sklearn.feature_extraction.text.CountVectorizer(binary=True)\n",
    "X_sw_lm_cv = count_vectorizer.fit_transform(X_sw_lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate a logistic regression model again\n",
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X_sw_lm_cv, y, test_size=0.25)\n",
    "\n",
    "best_clf = None\n",
    "best_score = 0\n",
    "\n",
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    clf = sklearn.linear_model.LogisticRegression(C=c, solver=\"lbfgs\", n_jobs=-1)\n",
    "    clf.fit(X_train, y_train)\n",
    "    score = clf.score(X_test, y_test)\n",
    "\n",
    "    if best_score < score:\n",
    "        best_clf = clf\n",
    "        best_score = score\n",
    "    \n",
    "    print(\"Accuracy for C=%0.2f: %0.3f\" % (c, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Most Informative Features (stop words, lemmatization):\\n\")\n",
    "\n",
    "show_most_informative_features(count_vectorizer, best_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use n-grams to also count 2-word sequences\n",
    "ngram_vectorizer = sklearn.feature_extraction.text.CountVectorizer(binary=True, ngram_range=(1,2))\n",
    "X_sw_lm_cv2 = ngram_vectorizer.fit_transform(X_sw_lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate a logistic regression model again\n",
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X_sw_lm_cv2, y, test_size=0.25)\n",
    "\n",
    "best_clf = None\n",
    "best_score = 0\n",
    "\n",
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    clf = sklearn.linear_model.LogisticRegression(C=c, solver=\"lbfgs\", n_jobs=-1)\n",
    "    clf.fit(X_train, y_train)\n",
    "    score = clf.score(X_test, y_test)\n",
    "\n",
    "    if best_score < score:\n",
    "        best_clf = clf\n",
    "        best_score = score\n",
    "    \n",
    "    print(\"Accuracy for C=%0.2f: %0.3f\" % (c, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Most Informative Features (stop words, lemmatization, 2-grams):\\n\")\n",
    "show_most_informative_features(ngram_vectorizer, best_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now include 2-word and 3-word sequences\n",
    "ngram_vectorizer = sklearn.feature_extraction.text.CountVectorizer(binary=True, ngram_range=(1,3))\n",
    "X_sw_lm_cv3 = ngram_vectorizer.fit_transform(X_sw_lm)\n",
    "\n",
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X_sw_lm_cv3, y, test_size=0.25)\n",
    "\n",
    "best_clf = None\n",
    "best_score = 0\n",
    "\n",
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    clf = sklearn.linear_model.LogisticRegression(C=c, solver=\"lbfgs\", n_jobs=-1)\n",
    "    clf.fit(X_train, y_train)\n",
    "    score = clf.score(X_test, y_test)\n",
    "\n",
    "    if best_score < score:\n",
    "        best_clf = clf\n",
    "        best_score = score\n",
    "    \n",
    "    print(\"Accuracy for C=%0.2f: %0.3f\" % (c, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Most Informative Features (stop words, lemmatization, 3-grams):\\n\")\n",
    "show_most_informative_features(ngram_vectorizer, best_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Model: stop words, lemmatization, n-grams, SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now use SVM instead of logistic regression\n",
    "ngram_vectorizer = sklearn.feature_extraction.text.CountVectorizer(binary=True, ngram_range=(1,3))\n",
    "X_sw_lm_cv3 = ngram_vectorizer.fit_transform(X_sw_lm)\n",
    "\n",
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X_sw_lm_cv3, y, test_size=0.25)\n",
    "\n",
    "best_clf = None\n",
    "best_score = 0\n",
    "\n",
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    clf = sklearn.svm.LinearSVC(C=c)\n",
    "    clf.fit(X_train, y_train)\n",
    "    score = clf.score(X_test, y_test)\n",
    "\n",
    "    if best_score < score:\n",
    "        best_clf = clf\n",
    "        best_score = score\n",
    "    \n",
    "    print(\"Accuracy for C=%0.2f: %0.3f\" % (c, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Most Informative Features (stop words, lemmatization, 3-grams):\\n\")\n",
    "show_most_informative_features(ngram_vectorizer, best_clf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (mlbd)",
   "language": "python",
   "name": "mlbd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
