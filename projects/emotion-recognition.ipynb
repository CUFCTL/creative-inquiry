{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emotion Recognition\n",
    "\n",
    "Authors: Greg Szrom, Ben Shealy\n",
    "\n",
    "In this notebook, we will show you how to create a neural network for emotion recognition. For this task, we used a dataset of faces from the UCI dataset repository. This dataset contains 20 individuals, each showing four different emotions: \"angry\", \"happy\", \"neutral\", and \"sad\". We trained a convolutional neural network (CNN) on this data using the emotions as labels.\n",
    "\n",
    "This project is a work in progress, so anyone is welcome to pick up this project and attempt to improve the results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns\n",
    "import skimage\n",
    "import sklearn\n",
    "import sklearn.metrics\n",
    "import sklearn.model_selection\n",
    "import sklearn.preprocessing\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the Data\n",
    "\n",
    "The first step is to acquire and process the data so that it can be fed to the CNN. There are several preprocessing steps which we must perform, including:\n",
    "\n",
    "- Remove bad data samples\n",
    "- Convert images from PGM to PPM, which can be read by `skimage`\n",
    "- Crop images from 128x120 to 120x120 so that they are square\n",
    "- Generate 90, 180, and 270 degree rotations of each image\n",
    "- Generate horizontal flips of each image (including rotated copies)\n",
    "- Reorganize images according to emotion instead of individual\n",
    "\n",
    "All of these tasks are easier to do in Bash instead of Python, so we will perform each step as a Bash script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%script bash\n",
    "\n",
    "# remove existing dataset files\n",
    "rm -rf faces.tar.gz faces\n",
    "\n",
    "# download and extract dataset from UCI repository\n",
    "wget -q http://archive.ics.uci.edu/ml/machine-learning-databases/faces-mld/faces.tar.gz\n",
    "tar -xf faces.tar.gz\n",
    "\n",
    "# remove some artifacts from dataset\n",
    "rm -rf faces/.anonr faces/**/*.bad faces/**/*_2.pgm faces/**/*_4.pgm\n",
    "\n",
    "# print the number of images in the dataset\n",
    "ls faces/**/*.pgm | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script bash\n",
    "\n",
    "# convert pgm files to ppm\n",
    "for f in faces/**/*.pgm; do\n",
    "    convert $f \"$(dirname $f)/$(basename $f .pgm).ppm\"\n",
    "done\n",
    "\n",
    "rm -rf faces/**/*.pgm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script bash\n",
    "\n",
    "# crop images to be square (120x120)\n",
    "for f in faces/**/*.ppm; do\n",
    "    convert $f -resize 120x120^ -gravity center -extent 120x120 $f\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script bash\n",
    "\n",
    "# generate rotations of each image at 90, 180, and 270\n",
    "for f in faces/**/*.ppm; do\n",
    "    convert $f -rotate  90 \"$(dirname $f)/090_$(basename $f)\"\n",
    "    convert $f -rotate 180 \"$(dirname $f)/180_$(basename $f)\"\n",
    "    convert $f -rotate 270 \"$(dirname $f)/270_$(basename $f)\"\n",
    "    mv $f \"$(dirname $f)/000_$(basename $f)\"\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script bash\n",
    "\n",
    "# generate horizontal flips of each image\n",
    "for f in faces/**/*.ppm; do\n",
    "    convert $f -flop \"$(dirname $f)/flop_$(basename $f)\"\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script bash\n",
    "\n",
    "# rearrange faces into subfolders by emotion\n",
    "EMOTIONS=\"angry happy neutral sad\"\n",
    "\n",
    "mv faces faces-old\n",
    "\n",
    "for EMOTION in ${EMOTIONS}; do\n",
    "    mkdir -p faces/${EMOTION}\n",
    "    mv faces-old/**/*_${EMOTION}_*.ppm faces/${EMOTION}\n",
    "done\n",
    "\n",
    "rm -rf faces-old"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data\n",
    "\n",
    "Now that the dataset is ready, we can load it into Python. In particular, we'll create two numpy arrays: `X` contains the images, and `y` contains the numerical label for each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# infer class names from the sub-directory names\n",
    "classes = os.listdir(\"faces\")\n",
    "\n",
    "# initialize empty data array and label array\n",
    "num_samples = 8 * 624\n",
    "X = np.empty((num_samples, 120, 120, 3), dtype=np.uint8)\n",
    "y = np.empty((num_samples,), dtype=np.int64)\n",
    "\n",
    "# iterate through sub-directories\n",
    "i = 0\n",
    "\n",
    "for k, class_name in enumerate(classes):\n",
    "    # get list of images in class k\n",
    "    filenames = os.listdir(\"faces/%s\" % class_name)\n",
    "    filenames = [\"faces/%s/%s\" % (class_name, f) for f in filenames]\n",
    "    \n",
    "    # load each image into numpy array\n",
    "    for fname in filenames:\n",
    "        X[i] = skimage.io.imread(fname)\n",
    "        y[i] = k\n",
    "        i += 1\n",
    "\n",
    "print(\"X:\", X.shape)\n",
    "print(\"y:\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the Data\n",
    "\n",
    "Before we do anything else with the data, let's visualize a few examples to make sure that everything looks good so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the size of the grid\n",
    "rows = 4\n",
    "cols = 4\n",
    "\n",
    "# select several random samples from dataset\n",
    "indices = np.random.choice(np.arange(len(X)), rows * cols)\n",
    "\n",
    "# plot the images in a grid\n",
    "plt.figure(figsize=(3 * cols, 3 * rows))\n",
    "\n",
    "for i in range(rows * cols):\n",
    "    index = indices[i]\n",
    "    \n",
    "    ax = plt.subplot(rows, cols, i + 1)\n",
    "    plt.imshow(X[index], cmap=\"gray\")\n",
    "    plt.title(\"label = %d\" % y[index])\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Train / Test Sets\n",
    "\n",
    "In order to train the neural network, we need to split the dataset into train and test sets. The training set will be used to train the neural network, and then the test set will be used to evaluate the network's ability to recognize emotions. We'll also normalize the dataset to be [0, 1] instead of [0, 255], which generally helps in the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the data\n",
    "X = X.astype(\"float32\") / 255.\n",
    "\n",
    "# convert labels into one-hot labels\n",
    "y = keras.utils.to_categorical(y, num_classes=4)\n",
    "\n",
    "# split dataset into train set and test set\n",
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# print shapes of train/test sets\n",
    "print(\"X_train: %s\" % str(X_train.shape))\n",
    "print(\"y_train: %s\" % str(y_train.shape))\n",
    "print(\"X_test: %s\" % str(X_test.shape))\n",
    "print(\"y_test: %s\" % str(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the CNN\n",
    "\n",
    "Now that our data is ready, we can create and train our neural network. Here also we have several options to play with, including:\n",
    "\n",
    "- Number of layers\n",
    "- Number of filters per layer\n",
    "- Optimizer\n",
    "- Batch size\n",
    "- Epochs\n",
    "\n",
    "See if you can improve the accuracy of the network by tweaking these parameters..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a basic convolutional neural network\n",
    "cnn = keras.models.Sequential() \n",
    "cnn.add(keras.layers.Conv2D(64, (3,3), padding=\"same\", activation=\"relu\", input_shape=(120,120,3)))\n",
    "cnn.add(keras.layers.MaxPooling2D(2, 2))\n",
    "cnn.add(keras.layers.Conv2D(128, (3,3), padding=\"same\", activation=\"relu\"))\n",
    "cnn.add(keras.layers.MaxPooling2D(2, 2))\n",
    "cnn.add(keras.layers.Conv2D(128, (3,3), padding=\"same\", activation=\"relu\"))\n",
    "cnn.add(keras.layers.MaxPooling2D(2, 2))\n",
    "cnn.add(keras.layers.Conv2D(128, (3,3), padding=\"same\", activation=\"relu\"))\n",
    "cnn.add(keras.layers.MaxPooling2D(2, 2))\n",
    "cnn.add(keras.layers.Conv2D(128, (3,3), padding=\"same\", activation=\"relu\"))\n",
    "cnn.add(keras.layers.Flatten())\n",
    "cnn.add(keras.layers.Dense(1024, activation=\"relu\"))\n",
    "cnn.add(keras.layers.Dense(4, activation=\"softmax\"))\n",
    "\n",
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the convolutional neural network\n",
    "cnn.compile(optimizer=\"sgd\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "history = cnn.fit(X_train, y_train, batch_size=32, epochs=20, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the CNN\n",
    "\n",
    "The final step is to evaluate our network using the test set. The network has not seen any of the data in the test set, so it should be a good way to tell whether the network has truly learned how to recognize the four emotions in this dataset.\n",
    "\n",
    "The most basic metric which we'll use first is accuracy, the percentage of test images that the network classifies correctly. However, in case the network doesn't get a high accuracy, we need to be able to dig deeper into what exactly the network got wrong. For this, we'll create a confusion matrix, which succinctly shows what the network predicted versus what the correct answer was, for each group of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print the raw predictions of the cnn on the test set\n",
    "# each value corresponds to how confident the network is that a sample belongs to a particular class\n",
    "y_pred = cnn.predict(X_test, verbose=0) \n",
    "\n",
    "print(\"%12s %12s %12s\" % (\"Confidence\", \"Predicted\", \"Actual\"))\n",
    "\n",
    "n_correct = 0\n",
    "\n",
    "for i in range(len(y_test)):\n",
    "    confidence = np.amax(y_pred[i])\n",
    "    y_pred_i = np.argmax(y_pred[i])\n",
    "    y_test_i = np.argmax(y_test[i])\n",
    "\n",
    "    if y_pred_i == y_test_i:\n",
    "        n_correct += 1\n",
    "        \n",
    "    print(\"%12.3f %12d %12d %12d\" % (confidence, y_pred_i, y_test_i, n_correct))\n",
    "        \n",
    "print(\"Accuracy: %0.3f\" % (n_correct / len(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    # Compute confusion matrix\n",
    "    cm = sklearn.metrics.confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    # apply normalization if specified\n",
    "    if normalize:\n",
    "        title = \"Confusion matrix (normalized)\"\n",
    "        cm = cm.astype(\"float32\") / cm.sum(axis=1)\n",
    "    else:\n",
    "        title = \"Confusion matrix (not normalized)\"\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation=\"nearest\", cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes,\n",
    "           yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel=\"True label\",\n",
    "           xlabel=\"Predicted label\")\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = \".2f\" if normalize else \"d\"\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax\n",
    "\n",
    "\n",
    "\n",
    "# plot confusion matrix to better understand the results\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "classes = [\"angry\", \"happy\", \"neutral\", \"sad\"]\n",
    "y_test2 = np.argmax(y_test, axis=1)\n",
    "y_pred2 = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# plot non-normalized confusion matrix\n",
    "plot_confusion_matrix(y_test2, y_pred2, classes=classes)\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plot_confusion_matrix(y_test2, y_pred2, classes=classes, normalize=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "At the time of this writing, the CNN only achieves a test accuracy of ~25%, which is about the same as random guessing. This remains the case even after extensive experimentation with the dataset (using data augmentation) and the CNN (adjusting the number of layers, etc.). We suspect that the dataset we chose may not be large enough for the CNN to be able to learn the four emotions, or that it may not be informative enough. For example, the images still contain a lot of background noise and the facial features themselves are very small in the image. Therefore, some future directions would be acquiring more training data, removing background noise, and possibly experimenting with other network architectures or different models entirely."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
