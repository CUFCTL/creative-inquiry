{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mask RCNN implementation\n",
    "\n",
    "Author: Brad Selee\n",
    "\n",
    "In this notebook we will train the Mask R-CNN object detection model on the Microsoft COCO dataset. You will need to install additional packages to your Anaconda environment for Mask R-CNN and the COCO dataset:\n",
    "```\n",
    "pip install mrcnn pycocotools\n",
    "```\n",
    "\n",
    "Mask RCNN implementation can be found here: https://github.com/matterport/Mask_RCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "import numpy as np\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "from mrcnn.config import Config\n",
    "from mrcnn.model import MaskRCNN, load_image_gt, mold_image\n",
    "from mrcnn.utils import compute_ap, extract_bboxes, Dataset\n",
    "from mrcnn.visualize import display_instances\n",
    "from pycocotools.coco import COCO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The number of unique objects you are detecting\n",
    "NUM_OBJECTS = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/matterport/Mask_RCNN/blob/master/mrcnn/config.py\n",
    "class ImageConfig(Config):\n",
    "    \"\"\" Training configuration \"\"\"\n",
    "    # define the name of the configuration\n",
    "    NAME = \"image_cfg\"\n",
    "    # Number of class (background + object1)\n",
    "    NUM_CLASSES = 1 + NUM_OBJECTS\n",
    "    # Number of training steps per epoch - similar to batch size\n",
    "    STEPS_PER_EPOCH = 50\n",
    "    # simplify GPU config\n",
    "    # Batch size is 1 (GPUs * images/GPU). - might be able to put up to 8 images on 1 gpu\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredictionConfig(Config):\n",
    "    \"\"\" Prediction configuration\"\"\"\n",
    "    # define the name of the configuration\n",
    "    NAME = \"image_cfg\"\n",
    "    # number of classes (background + object)\n",
    "    NUM_CLASSES = 1 + 1\n",
    "    # simplify GPU config\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    \"\"\" Required Dataset Class for Mask RCNN \"\"\"\n",
    "    \n",
    "    def load_dataset(self, dataset_dir, is_train=True):\n",
    "        \"\"\" Load the dataset definitions \"\"\"\n",
    "        self.add_class(\"dataset\", 1, \"kangaroo\")\n",
    "        # define data locations\n",
    "        images_dir = dataset_dir + '/images/'\n",
    "        annotations_dir = dataset_dir + '/annots/'\n",
    "        # loop through images in directory\n",
    "        for filename in os.listdir(images_dir):\n",
    "            # extract image id\n",
    "            image_id = filename[:-4]\n",
    "            # skip bad images\n",
    "            if image_id in ['00090']:\n",
    "                continue\n",
    "            # skip all images after 150 if we are building the train set\n",
    "            if is_train and int(image_id) >= 150:\n",
    "                continue\n",
    "            # skip all images before 150 if we are building the test/val set\n",
    "            if not is_train and int(image_id) < 150:\n",
    "                continue\n",
    "            img_path = images_dir + filename\n",
    "            ann_path = annotations_dir + image_id + '.xml'\n",
    "            # add to dataset\n",
    "            self.add_image('dataset', image_id=image_id, path=img_path, annotation=ann_path)\n",
    "\n",
    "    \n",
    "    def extract_boxes(self, filename):\n",
    "        \"\"\" Extract bounding boxes from an annotation file \"\"\" \n",
    "        # load and parse the file\n",
    "        tree = ET.parse(filename)\n",
    "        # get the root of the document\n",
    "        root = tree.getroot()\n",
    "        # extract each bounding box\n",
    "        boxes = list()\n",
    "        for box in root.findall('.//bndbox'):\n",
    "            xmin = int(box.find('xmin').text)\n",
    "            ymin = int(box.find('ymin').text)\n",
    "            xmax = int(box.find('xmax').text)\n",
    "            ymax = int(box.find('ymax').text)\n",
    "            coors = [xmin, ymin, xmax, ymax]\n",
    "            boxes.append(coors)\n",
    "        # extract image dimensions\n",
    "        width = int(root.find('.//size/width').text)\n",
    "        height = int(root.find('.//size/height').text)\n",
    "        return boxes, width, height\n",
    "\n",
    "\n",
    "    def load_mask(self, image_id):\n",
    "        \"\"\" Load the masks for an image \n",
    "    \n",
    "            A mask is a binary image.\n",
    "            0's where the object isn't and \n",
    "            1's where the object is using the boundary boxes.\n",
    "        \"\"\"\n",
    "        # get details of image\n",
    "        info = self.image_info[image_id]\n",
    "        # define box file location\n",
    "        path = info['annotation']\n",
    "        # load XML\n",
    "        boxes, w, h = self.extract_boxes(path)\n",
    "        # create one array for all masks, each on a different channel\n",
    "        masks = np.zeros([h, w, len(boxes)], dtype='uint8')\n",
    "        # create masks\n",
    "        class_ids = list()\n",
    "        for i in range(len(boxes)):\n",
    "            box = boxes[i]\n",
    "            row_s, row_e = box[1], box[3]\n",
    "            col_s, col_e = box[0], box[2]\n",
    "            masks[row_s:row_e, col_s:col_e, i] = 1\n",
    "            class_ids.append(self.class_names.index('kangaroo'))\n",
    "        return masks, np.asarray(class_ids, dtype='int32')\n",
    "\n",
    "   \n",
    "    def image_reference(self, image_id):\n",
    "        \"\"\" Load an image reference - returns path of image \"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        return info['path']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(dataset, model, cfg):\n",
    "    \"\"\" Calculate the mAP for a model on a given dataset \"\"\"\n",
    "    APs = list()\n",
    "    for image_id in dataset.image_ids:\n",
    "        # load image, bounding boxes and masks for the image id\n",
    "        image, image_meta, gt_class_id, gt_bbox, gt_mask = load_image_gt(dataset, cfg, image_id, use_mini_mask=False)\n",
    "        # convert pixel values (e.g. center)\n",
    "        scaled_image = mold_image(image, cfg)\n",
    "        # convert image into one sample\n",
    "        sample = np.expand_dims(scaled_image, 0)\n",
    "        # make prediction\n",
    "        yhat = model.detect(sample, verbose=0)\n",
    "        # extract results for first sample\n",
    "        r = yhat[0]\n",
    "        # calculate statistics, including AP\n",
    "        AP, _, _, _ = compute_ap(gt_bbox, gt_class_id, gt_mask, r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n",
    "        # store\n",
    "        APs.append(AP)\n",
    "    # calculate the mean AP across all images\n",
    "    mAP = np.mean(APs)\n",
    "    return mAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_boxes(filename):\n",
    "    \"\"\" Function to extract bounding boxes from an annotation file \"\"\"\n",
    "    # load and parse the file\n",
    "    tree = ET.parse(filename)\n",
    "    # get the root of the document\n",
    "    root = tree.getroot()\n",
    "    # extract each bounding box\n",
    "    boxes = list()\n",
    "    for box in root.findall('.//bndbox'):\n",
    "        xmin = int(box.find('xmin').text)\n",
    "        ymin = int(box.find('ymin').text)\n",
    "        xmax = int(box.find('xmax').text)\n",
    "        ymax = int(box.find('ymax').text)\n",
    "        coors = [xmin, ymin, xmax, ymax]\n",
    "        boxes.append(coors)\n",
    "    # extract image dimensions\n",
    "    width = int(root.find('.//size/width').text)\n",
    "    height = int(root.find('.//size/height').text)\n",
    "    return boxes, width, height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_actual_vs_predicted(dataset, model, cfg, n_images=5):\n",
    "    \"\"\" Plot a number of photos with ground truth and predictions \"\"\"\n",
    "    \n",
    "    plt.figure(figsize=(plot_size * 2, plot_size * n_images))\n",
    "    \n",
    "    # load image and mask\n",
    "    for i in range(n_images):\n",
    "        # load the image and mask\n",
    "        image = dataset.load_image(i)\n",
    "        mask, _ = dataset.load_mask(i)\n",
    "        # convert pixel values (e.g. center)\n",
    "        scaled_image = mold_image(image, cfg)\n",
    "        # convert image into one sample\n",
    "        sample = np.expand_dims(scaled_image, 0)\n",
    "        # make prediction\n",
    "        yhat = model.detect(sample, verbose=0)[0]\n",
    "        # define subplot\n",
    "        plt.subplot(n_images, 2, i*2+1)\n",
    "        # plot raw pixel data\n",
    "        plt.imshow(image)\n",
    "        plt.title('Actual')\n",
    "        # plot masks\n",
    "        for j in range(mask.shape[2]):\n",
    "            plt.imshow(mask[:, :, j], cmap='gray', alpha=0.3)\n",
    "        # get the context for drawing boxes\n",
    "        plt.subplot(n_images, 2, i*2+2)\n",
    "        # plot raw pixel data\n",
    "        plt.imshow(image)\n",
    "        plt.title('Predicted')\n",
    "        ax = plt.gca()\n",
    "        # plot each box\n",
    "        for box in yhat['rois']:\n",
    "            # get coordinates\n",
    "            y1, x1, y2, x2 = box\n",
    "            # calculate width and height of the box\n",
    "            width, height = x2 - x1, y2 - y1\n",
    "            # create the shape\n",
    "            rect = Rectangle((x1, y1), width, height, fill=False, color='red')\n",
    "            # draw the box\n",
    "            ax.add_patch(rect)\n",
    "    # show the figure\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Parse XML File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"Mask_RCNN/kangaroo/annots/00001.xml\"\n",
    "boxes, width, height = extract_boxes(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(boxes)\n",
    "print(width)\n",
    "print(height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train set\n",
    "train_set = ImageDataset()\n",
    "train_set.load_dataset('Mask_RCNN/kangaroo', is_train=True)\n",
    "train_set.prepare()\n",
    "print('Train: %d' % len(train_set.image_ids))\n",
    "\n",
    "# Test/val set\n",
    "test_set = ImageDataset()\n",
    "test_set.load_dataset('Mask_RCNN/kangaroo', is_train=False)\n",
    "test_set.prepare()\n",
    "print('Test: %d' % len(test_set.image_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Images and Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load an image\n",
    "image_id = 0\n",
    "image = train_set.load_image(image_id)\n",
    "print(image.shape)\n",
    "# Load image mask\n",
    "mask, class_ids = train_set.load_mask(image_id)\n",
    "print(mask.shape)\n",
    "# mask.shape[2] => number of bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot image\n",
    "plt.imshow(image)\n",
    "# Plot mask\n",
    "plt.imshow(mask[:, :, 0], cmap='gray', alpha=0.5) # alpha => how dominant the image is\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Several Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = 3\n",
    "cols = 3\n",
    "plot_size = 3\n",
    "\n",
    "indices = np.random.choice(np.arange(len(train_set.image_ids)), rows * cols)\n",
    "plt.figure(figsize=(plot_size * cols, plot_size * rows))\n",
    "for i in range(rows*cols):\n",
    "    index = indices[i]\n",
    "    \n",
    "    # define subplot\n",
    "    plt.subplot(rows, cols, i + 1)\n",
    "    # plot raw pixel data\n",
    "    image = train_set.load_image(index)\n",
    "    plt.imshow(image)\n",
    "    # plot all masks\n",
    "    mask, _ = train_set.load_mask(index)\n",
    "    # Loop through all masks in image\n",
    "    for j in range(mask.shape[2]):\n",
    "        plt.imshow(mask[:, :, j], cmap='gray', alpha=0.3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run through image_info to make sure they are loaded properly\n",
    "# for image_id in train_set.image_ids:\n",
    "for i in range(10): #first 10 image_info's\n",
    "    image_id = train_set.image_ids[i]\n",
    "    # load image info\n",
    "    info = train_set.image_info[image_id]\n",
    "    # display on the console\n",
    "    print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define image id\n",
    "image_id = 0\n",
    "# load the image\n",
    "image = train_set.load_image(image_id)\n",
    "# load the masks and the class ids\n",
    "mask, class_ids = train_set.load_mask(image_id)\n",
    "# extract bounding boxes from the masks\n",
    "bbox = extract_bboxes(mask)\n",
    "# display image with masks and bounding boxes\n",
    "display_instances(image, bbox, mask, class_ids, train_set.class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Mask R-CNN\n",
    "Uses Transfer Learning rather than fitting model from scratch. Giving it a pretrained weights allows the model to have a starting point, then it can be tailored to a specfic dataset. The coco dataset is a good starting place for pretrained weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ImageConfig()\n",
    "config.display()\n",
    "# define the model and save training checkpoints in current directory\n",
    "# load weights (mscoco) and exclude the output layers\n",
    "# exclude class-specific output layers will be removed so that new output layers can be defined and trained\n",
    "# train weights (output layers or 'heads')\n",
    "model = MaskRCNN(mode='training', model_dir='./checkpoints', config=config)\n",
    "model.load_weights('mask_rcnn_coco.h5', by_name=True, exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\",  \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "model.train(train_set, test_set, learning_rate=config.LEARNING_RATE, epochs=5, layers='heads')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Model\n",
    "\n",
    "The goal is to predict bounding boxes. Performance of an object recognition task is often is evaulated using the mean absolute precision (mAP). Comparing the actual and predicted bounding boxes gives a good estimate of accuracy. Mathematically, it can be calculated by dividing the area of the overlap by the total area of both bounding boxes. Or, the intersection divided by the union, IoU. A perfect IoU is 1. A positive prediction is considered greater than 0.\n",
    "\n",
    "A mAP above 90% or 95% is a good score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create config and define the model\n",
    "prediction_config = PredictionConfig()\n",
    "model = MaskRCNN(mode='inference', model_dir='./predictions', config=prediction_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model weights\n",
    "model.load_weights('mask_rcnn_image_cfg_0005.h5', by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model on train dataset\n",
    "train_mAP = evaluate_model(train_set, model, prediction_config)\n",
    "print(\"Train mAP: %.3f\" % train_mAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model on test dataset\n",
    "test_mAP = evaluate_model(test_set, model, prediction_config)\n",
    "print(\"Test mAP: %.3f\" % test_mAP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecting Objects in New Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot predictions for train dataset\n",
    "plot_actual_vs_predicted(train_set, model, prediction_config)\n",
    "# plot predictions for test dataset\n",
    "plot_actual_vs_predicted(test_set, model, prediction_config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (mlbd)",
   "language": "python",
   "name": "mlbd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
