{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock Price Forecasting with LSTM\n",
    "\n",
    "Authors: Matthew Franci, Ben Shealy\n",
    "\n",
    "In this notebook we will demonstrate how to perform times series forecasting with an LSTM. We'll use historical stock price data for a few major companies, which can be downloaded from Yahoo Finance:\n",
    "\n",
    "- [AAPL](https://finance.yahoo.com/quote/AAPL/history)\n",
    "- [GDX](https://finance.yahoo.com/quote/GDX/history)\n",
    "- [QQQ](https://finance.yahoo.com/quote/QQQ/history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% Load In Supporting Modules\n"
    }
   },
   "outputs": [],
   "source": [
    "# pandas imports\n",
    "import pandas as pd\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "\n",
    "# numpy import\n",
    "import numpy as np\n",
    "\n",
    "# matplotlib import\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# sklearn imports\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# keras import\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stock Class\n",
    "\n",
    "We will create a `Stock` class which will provide all of the necessary functionality for any stock price dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% Stock Class\n"
    }
   },
   "outputs": [],
   "source": [
    "class Stock:\n",
    "    # CONSTRUCTOR\n",
    "    def __init__(self, stockName, filePath):\n",
    "        # read data in filePath, header at first row, dates on first column, dates used as the index\n",
    "        self.data = pd.read_csv(filePath, header = 0, parse_dates=[0], index_col = 0, squeeze= True)\n",
    "        # drop any present NA values\n",
    "        self.data = self.data.dropna(0)\n",
    "        \n",
    "        self.name = stockName\n",
    "        \n",
    "        # Member Variables relating to the Core LSTM Branch\n",
    "        self.train_samplesX = np.array\n",
    "        self.test_samplesX = np.array\n",
    "        self.train_samplesY = np.array\n",
    "        self.test_samplesY = np.array\n",
    "        self.scaler = MinMaxScaler\n",
    "        \n",
    "        # Normalized data for the Core LSTM Branch\n",
    "        self.normalizedData = np.array\n",
    "        self.normDataHistory = np.array\n",
    "        self.nextDayVals = np.array\n",
    "        self.nextDaysVals_test = np.array\n",
    "        self.nextDayValsNorm = np.array\n",
    "        self.model = keras.Model()\n",
    "        \n",
    "        # Member Variables for the Tech Indicators LSTM Branch\n",
    "        self.indicators = np.array\n",
    "        self.indicatorsNorm = np.array\n",
    "        self.indicators_train = np.array\n",
    "        self.indicators_test = np.array\n",
    "        self.indicatorScaler = MinMaxScaler\n",
    "        \n",
    "        # Default Values for \"Global\" Parameters\n",
    "        # testProp: test vs. train proportion - .2 means 20% will be used for testing, 80% for training\n",
    "        self.testProp = .2\n",
    "        # numLag: where the \"expected\" value is \n",
    "        self.numLag = 1\n",
    "        # numSeq: size to make each LSTM sample\n",
    "        self.numSeq = 1\n",
    "        # numEpochs - number of epochs on which to train the model\n",
    "        self.numEpochs = 1\n",
    "        # numNeurons - number of neurons to use with the modlel\n",
    "        self.numNeurons = 1\n",
    "        # batchSize - model batch size\n",
    "        self.batchSize = 32\n",
    "\n",
    "    # FUNCTION show_head() - displays the head of the Stock's dataframe to the console\n",
    "    def show_head(self):\n",
    "        print(self.data.head())\n",
    "\n",
    "    # FUNCTION plot() - basic plot of Stock's longitudinal open price and volume\n",
    "    def plot(self):\n",
    "        register_matplotlib_converters()\n",
    "        fig, (ax1,ax2) = plt.subplots(1,2,figsize=(21,3),dpi=300)\n",
    "        \n",
    "        ax1.set_title(self.name + \" Longitudinal Open Prices\")\n",
    "        ax1.plot(self.data['Open'][::30])\n",
    "        ax1.set_xlabel('Date')\n",
    "        ax1.set_ylabel('Stock Price USD [$]')\n",
    "        \n",
    "        ax2.set_title(self.name + \" Longitudinal Volume\")\n",
    "        ax2.plot(self.data['Volume'][::30])\n",
    "        ax2.set_xlabel('Date')\n",
    "        ax2.set_ylabel('Stock Volume')\n",
    "        fig.savefig(self.name+\"_plot.png\")\n",
    "        plt.show()\n",
    "        \n",
    "    # FUNCTION prepare_samples() - scales Stock data to (0,1) range, creates core LSTM samples\n",
    "    def prepare_samples(self):\n",
    "        self.scaler = MinMaxScaler(feature_range=(0,1))\n",
    "        self.normalizedData = self.scaler.fit_transform(self.data)\n",
    "        \n",
    "        self.normDataHistory = np.array([self.normalizedData[i : i + self.numSeq].copy() \n",
    "                                         for i in range(len(self.normalizedData)-self.numSeq)])\n",
    "        self.nextDayValsNorm = np.array([self.normalizedData[:,0][i+self.numSeq].copy() \n",
    "                                         for i in range(len(self.normalizedData)-self.numSeq)])\n",
    "        self.nextDayValsNorm = np.expand_dims(self.nextDayValsNorm,-1)\n",
    "        \n",
    "        self.nextDayVals = np.array([self.data.values[:,0][i+ self.numSeq].copy() \n",
    "                                     for i in range(len(self.data) - self.numSeq)])\n",
    "        \n",
    "        self.nextDayVals = np.expand_dims(self.nextDayVals,-1)\n",
    "        \n",
    "        yNormalizer = MinMaxScaler()\n",
    "        yNormalizer.fit(self.nextDayVals)\n",
    "        \n",
    "        self.scaler = yNormalizer\n",
    "        \n",
    "        assert self.normDataHistory.shape[0] == self.nextDayValsNorm.shape[0]\n",
    "    \n",
    "    # FUNCTION prepare_indicators() - creates normalized indicator data\n",
    "    # precondition - prepare_samples() has been run successfully\n",
    "    def prepare_indicators(self):\n",
    "        indicators = []\n",
    "        for day in self.normDataHistory:\n",
    "            sma = np.mean(day[:,4])\n",
    "            indicators.append(np.array([sma]))\n",
    "            \n",
    "        self.indicators = np.array(indicators)\n",
    "        \n",
    "        self.indicatorScaler = MinMaxScaler()\n",
    "        self.indicatorsNorm = self.indicatorScaler.fit_transform(self.indicators)\n",
    "\n",
    "    # FUNCTION split_data() - splits the Core LSTM Layer data into its testing and training sets\n",
    "    # precondition - prepare_samples() has been run successfully\n",
    "    def split_data(self):\n",
    "        split = self.normDataHistory.shape[0]-int(self.normDataHistory.shape[0] * self.testProp)\n",
    "        \n",
    "        self.train_samplesX, self.test_samplesX = self.normDataHistory[:split], self.normDataHistory[split:]\n",
    "        self.train_samplesY, self.test_samplesY = self.nextDayValsNorm[:split],self.nextDayValsNorm[split:]\n",
    "        self.nextDayVals_test = self.nextDayVals[split:]\n",
    "    \n",
    "    # FUNCTION split_indicator_data() - splits the indicator layer data into its testing and trianing sets\n",
    "    # precondition - prepare_indicators() has been run successfully\n",
    "    def split_indicator_data(self):\n",
    "        split = self.indicatorsNorm.shape[0] - int(self.indicatorsNorm.shape[0] * self.testProp)\n",
    "        \n",
    "        self.indicators_train, self.indicators_test = self.indicatorsNorm[:split],self.indicatorsNorm[split:]\n",
    "\n",
    "    # FUNCTION set_globals() - lets the user modify the test proprtion, batch size, sequence size, number of neurons,\n",
    "    #                           and number of training epochs\n",
    "    # POTENTIAL TO-DO: add functions that modify each of these parameters individually\n",
    "    def set_globals(self,testProp,batchSize,numSeq,numNeurons,numEpochs):\n",
    "        self.testProp = testProp\n",
    "        self.batchSize = batchSize\n",
    "        self.numSeq = numSeq\n",
    "        self.numNeurons = numNeurons\n",
    "        self.numEpochs = numEpochs\n",
    "\n",
    "    # FUNCTION fit_LSTM() - creates the full keras model, taking into the \"global\" parameters\n",
    "    def fit_LSTM(self):\n",
    "        lstm_input = keras.layers.Input(shape=(self.numSeq,self.data.shape[1]),name='lstm_input')\n",
    "        dense_input = keras.layers.Input(shape=(self.indicators.shape[1],),name='ind_input')\n",
    "        \n",
    "        x = keras.layers.LSTM(self.numNeurons,name='LSTM_0')(lstm_input)\n",
    "        x = keras.layers.Dropout(0.2,name='lstm_dropout_0')(x)\n",
    "        lstm_branch = keras.Model(inputs=lstm_input,outputs=x)\n",
    "        \n",
    "        y = keras.layers.Dense(64,name='dense_0')(dense_input)\n",
    "        y = keras.layers.Activation('sigmoid',name='sigmoid_0')(y)\n",
    "        y = keras.layers.Dense(1,name='dense_1')(y)\n",
    "        \n",
    "        ind_branch = keras.Model(inputs=dense_input,outputs=y)\n",
    "        \n",
    "        complete = keras.layers.concatenate([lstm_branch.output,ind_branch.output],name='complete')\n",
    "        \n",
    "        z = keras.layers.Dense(64, activation = \"sigmoid\",name='dense_pooling')(complete)\n",
    "        z = keras.layers.Dense(1,activation='linear',name='dense_out')(z)\n",
    "    \n",
    "        self.model = keras.Model(inputs=[lstm_branch.input,ind_branch.input],outputs=z)\n",
    "        \n",
    "        self.model.compile(optimizer='adam',loss='mse')\n",
    "        \n",
    "        # line below creates the diagram of the LSTM model - not needed for every run\n",
    "        # plot_model(model,to_file='model.png')\n",
    "        \n",
    "        self.model.fit(x=[self.train_samplesX,self.indicators_train],y=self.train_samplesY,\n",
    "                       batch_size=self.batchSize,epochs=self.numEpochs,shuffle=True,validation_split=.1)\n",
    "        \n",
    "        # built-in keras evaluation, replaced with MSE and R^2 in evaluate_forecasts() function\n",
    "        #evaluation = self.model.evaluate([self.test_samplesX,self.indicators_test],self.test_samplesY)\n",
    "        #print(evaluation)\n",
    "\n",
    "    # FUNCTION evaluate_forecasts() - generates MSE and R^2, and plots predicted vs. actual curve\n",
    "    # POTENTIAL TO-DO: split the evaluation metrics and evaluation plots into two functions\n",
    "    def evaluate_forecasts(self):\n",
    "        # np array of predicted values from the model\n",
    "        predictedPrices = self.model.predict([self.test_samplesX,self.indicators_test])\n",
    "        predictedPrices = self.scaler.inverse_transform(predictedPrices)\n",
    "        \n",
    "        MSE = np.mean(np.square(self.nextDayVals_test - predictedPrices))\n",
    "        MSE_scaled = MSE / (np.max(self.nextDayVals_test) - np.min(self.nextDayVals_test)) * 100\n",
    "        print(\"MSE Score: \" +MSE_scaled)\n",
    "        \n",
    "        rSquared = r2_score(self.nextDayVals_test,predictedPrices)\n",
    "        print(\"R^2 Score: \" +rSquared)\n",
    "        \n",
    "        fig = plt.figure(figsize=(20,10),dpi=300)\n",
    "        actual = plt.plot(self.nextDayVals_test,label='actual')\n",
    "        predicted = plt.plot(predictedPrices,label='predicted')\n",
    "        plt.legend(['Actual','Predicted'])\n",
    "        plt.show()\n",
    "        fig.savefig(self.name+\"forecastplot\"+self.numEpochs+\".png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecast Stock Prices\n",
    "\n",
    "Now we will apply our forecasting model to several major stocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% AAPL Stock\n"
    }
   },
   "outputs": [],
   "source": [
    "AAPL = Stock(\"AAPL\",\"AAPL.csv\")\n",
    "AAPL.set_globals(.15,32,5,50,5)\n",
    "AAPL.show_head()\n",
    "AAPL.plot()\n",
    "AAPL.prepare_samples()\n",
    "AAPL.prepare_indicators()\n",
    "AAPL.split_data()\n",
    "AAPL.split_indicator_data()\n",
    "AAPL.fit_LSTM()\n",
    "AAPL.evaluate_forecasts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%% GDX ETF\n"
    }
   },
   "outputs": [],
   "source": [
    "GDX = Stock(\"GDX\",\"GDX.csv\")\n",
    "GDX.set_globals(.15,32,10,50,5)\n",
    "GDX.show_head()\n",
    "GDX.plot()\n",
    "GDX.prepare_samples()\n",
    "GDX.prepare_indicators()\n",
    "GDX.split_data()\n",
    "GDX.split_indicator_data()\n",
    "GDX.fit_LSTM()\n",
    "GDX.evaluate_forecasts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% QQQ ETF\n"
    }
   },
   "outputs": [],
   "source": [
    "QQQ = Stock(\"QQQ\",\"QQQ.csv\")\n",
    "QQQ.set_globals(.15,32,5,50,50)\n",
    "QQQ.show_head()\n",
    "QQQ.plot()\n",
    "QQQ.prepare_samples()\n",
    "QQQ.prepare_indicators()\n",
    "QQQ.split_data()\n",
    "QQQ.split_indicator_data()\n",
    "QQQ.fit_LSTM()\n",
    "QQQ.evaluate_forecasts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
